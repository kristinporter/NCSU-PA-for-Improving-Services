---
title: "Handling missing data - predictors"
---

![](images/jigsaw.jpg){fig-align="left" width="6in"}\
Here we focus on how to handle missingness in variables that are potential predictors for our learners. Some implementations of machine learning algorithms have a built-in way to handle missing data. Others either will not run if the model is fed in data containing missingness or will drop observations with any missing values. We will address missing values before using any modeling functions in R so that the approach will not vary across modeling approaches. Addressing missing data consistently allows us to make a fair comparison of differnt models' performances.

There are many different methods for managing missing data. They typically involve "filling in" - or "imputing" - missing data points with plausible values. Imputation can be a valuable approach to consider, and it is discussed below. But imputation should not be the primary strategy. Instead, we should recognize that **missingness may be informative.** Therefore, it is valuable to capture the missingness in our modeling.

### Capturing information in missingness

The idea here is pretty simple. Data may be missing for a reason - or for multiple reasons, which may be related to the outcome we are trying to predict, even if in a small way.

For example, when predicting whether a student will graduate on time, their standardized math score and the resulting proficiency level are potential predictors. Here the math score is on a scale from 0 to 100, and a proficiency value of 1 indicates the student scored "below proficient"; a value of 2 indicates the student scored as "proficient;" and a value of 3 indicates the student scored "above proficient." Students who have missing values for these variables may not have taken the test. Perhaps they were absent on the day of the test and the day of the make-up. It is possible some of these students tend to be absent more often than the average student. Therefore, missingness on a math test may tell us something about a student's level of absenteeism. Or, perhaps some students are exempt from the test because they are on a different math track.

We have no way of knowing the reasons students are missing data for variables with information about the math standardized test. But...

-   It is quite possible that those with missing data are different than those entered data; therefore imputation based on entered data would likely be biased. And...

-   Students with missing data may be less or more likely to graduate on time. Therefore, we want to allow for missingness to be predictive of the outcome of interest.

To capture the missingness information in our modeling, we can take the following approaches

1.  For categorical variables, we add a category for the missingness.

    -   Note if our raw variable (before accounting for missingness) is an "ordered" categorical variable, for which the categories have a clear and meaningful order or scale, then adding a category for missingness means that our newly formatted variable is an "unordered" categorical variable. In R, a `factor` (a class of an R object or of a column in a data frame) is used to represent categorical variables. (By default a factor treats values as unordered categorical variables, although factors can also be ordered.)

    -   Equivalently, we can create a set of dummies (binary variables with values 0 or 1 indicating whether an observation belongs to each category or not). Note, when we create a set of dummies, we leave one category out, as a reference category. For some modeling approaches, including all possible categories can create unstable estimation. So for example, we might create a set of three dummies indicating (1) proficient,  (2) above proficient, and (3) missing proficiency information (leaving the 4th category of below proficiency out).


Below, we see how this looks in a revised R data frame:

```{r echo=FALSE}

# Creating a mini data frame with missing values
toydata <- data.frame(
  ID = c(1, 2, 3, 4, 5),
  School = c("A","A","B","B","B"),
  MathScore = c(40,60,NA,80,60),
  Math.Proficient = c(0,1,0,0,1),
  Math.AboveProficient = c(0,1,0,1,0),
  Math.Missing = c(0,0,1,0,0),
  GradOnTime = c(1,0,1,0,NA)
)

print(toydata)
```

    -   If we have a small category, we will want to combine it with another category. For example, if there are just a few missing values, we might create a factor variable where one category is "proficient"; another is "above proficient"; and the other is "either below proficient or missing proficiency information" - or we create two dummies (leaving one category out).
    
    -   If missingness is a very large category, this may indicate a problem with the reliability of the variable. Variables with large amounts of missing data should perhaps be eliminated from analyses - but this is an issue to discuss with those who have expertise with the data systems and data entry processess. 



2.  For continuous variables, we can turn create a new, transformed categorical variable. That is, if our data only contained the math test score, to address missingness, we can turn it into a variable that captures different levels and missingness as above. Converting continuous variables to categorical variables may be desirable for extracting predictive information as well. For example, whether a student scored at a proficient level or not may be more predictive than their raw score.

3.  For continuous variables, we can also do a combination of imputation and creating a dummy to capture missingness. This method, "dummy variable adjustment" (Cohen and Cohen, 1985) is illustrated below. Here we impute the missing math scores with the mean of the nonmissing math scores, and we create a dummy variable that is 1 for observations with inputations and 0 otherwise. 

    ```{r echo=FALSE}

    # Creating a mini data frame with missing values
    toydata <- data.frame(
      ID = c(1, 2, 3, 4, 5),
      School = c("A","A","B","B","B"),
      MathScore = c(40,60,NA,80,60),
      Impute.MathScore = c(40,60,60,80,60),
      Miss.MathScore = c(0,0,1,0,0),
      GradOnTime = c(1,0,1,0,NA)
    )

    print(toydata)
    ```

    When we use this "dummy variable adjsutment," we include both the new variable with imputed values and the new dummy in our modeling. Note that in a regression, the choice of the value used for imputation does not affect the coefficient of `Miss.MathScore` or `Impute.MathScore`. The coefficient for `Impute.MathScore` can be regarded as an estimate of the effect of the math score among the subgroup of those observations that have complete math score data. The only aspect of the model that depends on the choice of the imputation value is the coefficient on the missing dummies. When we impute with the mean (or the median or mode) of non-missing values, the coefficient of a missingness dummy can be interpreted as the predicted value of the outcome for individuals with missing data on X minus the predicted value of Y for individuals at the mean of X, controlling for other covariates in the model.

    There has been a considerable amount of criticism focused on this approach in the literature. Jones (1996) and Allison (2002) show that, generally in studies using observational data, this approach leads to biased estimates of the coefficients in the regression model.9 Despite the uniform criticism of the method in the literature, however, we believe this approach still warrants consideration in the special case of random assignment evaluations.

Here is some R code to illustrate. Here, we have a variable for math test level. Level 1 is not proficient, while Level 2 is proficient. Two of the 5 students do not have any informtion entered in the data.

```{r echo=FALSE}
math.test <- c(1,2,NA,1,2)
math.test.levels <- as.factor(c("1","2","0","1","2"))
math.test.proficient <- c(0,1,0,0,1)
math.test.missing <- c(0,0,1,0,0)
demo.math.test <- data.frame(math.test,math.test.levels,math.test.proficient,math.test.missing)

print(demo.math.test)

```


### Imputation

If it is missing not at random (MNAR), we recommend using an imputation approach along with creating a missingness indicator to capture informative missingness. In the companion predictive analytics tool, we have made the default assumption of missing not at random.

For example, a simple version of imputation is to replace missing values of continuous variables with mean or median of the non-missing values, or to replace missing values of categorical variables with the mode. While this practice solves the operational difficulty of missing data, it can potentially create problems. On the last page, we reviewed a list of of reasons why data may be missing. Many of reasons suggest that units of observations (e.g. individuals) with missing data may be different from units without missing data. People who are resistant to reporting their wage may be more likely to have a low wage. Data collection at one site of a business may be more reliable at entering data than another site.

Therefore, if we replace missing values with the mean of nonmissing values, this mean is not a good estimate because it was computed for a different population. When estimating statistical parameters, imputation can introduce bias - that is, it can lead to inflated or undervalued estimates. When fitting a predictive model, this practice can lead to diminished performance because the relationships between predictors (e.g. age and wage) and an outcome (e.g., job retention) can be faulty.

Some analysts focus on doing a really good job at finding plausible values for their imputation. This is a very active area in statistical research. For example, the imputed values may be estimated by modeling - using information throughout the dataset to come up with more plausible values because they are similar to observations with a similar profile across numerous measures (variables). With an approach called "multiple imputation," the modeling for the missing values is repeated multiple times, resulting in multiple complete data sets. This repeated modeling accounts for both sampling uncertainty as well as modeling (specification) uncertainty of imputed values. (E.g., Gelman and Hill (2007)). The multiple complete datasets can be combined in different ways or results from repeated analyses of the multiple datasets can be combined. Multiple imputation methods reduce but do not eliminate bias in filled-in values.


---
title: "The importance of a proof-of-concept"
---
![](images/shutterstock_poc.jpg){fig-align="center" width="8in"}

After we have scoped our predictive analytics project, the next step is to conduct a "proof-of-concept." That is, before getting too invested in incorporating predictive analytics into systems of service improvement, we need to investigate the following:

1.  **Given the available data, how well can we predict our outcome of interest?**

    When investigating this question, we will want to consider various metrics of model performance, which we will turn to in a later section. We will be concerned with how well our predictive models help us identify those who truly are at risk. We may also be concerned with the extent to which our model makes mistakes - either designating at-risk individuals as being not-at-risk, or not-at-risk individuals as being at-risk.

2.  **Given the available data, to what extent is there bias in our predictions?**

    When investigating this question, we will want to consider various metrics of bias, which we will also turn to in a later section. Here we will be concerned with whether and by how much model performance varies for different groups.

3.  **To what extent do more complex predictive models improve upon a simple one or upon current practice?**

    When investigating this question, our focus is on contrasting predictive capabilities and potential biases across various prediction approaches. A simple predictive model might encompass just a handful of measures, which are combined and weighted in a straightforward manner. For instance, individuals meeting specific criteria based on these measures might be predicted to realize the outcome of interest. Alternatively, these metrics could be plugged into a regression model to estimate their relationship with the outcome. We may add complexity to the predictive modeling by adding more measuers and by using advanced, data-driven algorithms. The crux then lies in weighing the pros and cons when comparing different models. Should a more complex model yield superior results compared to a simpler one, it prompts a consideration: Are the improvements significant enough to offset potential drawbacks in terms of transparency and explainability? Additionally, do these improvements outweigh any potential challenges in implementing and sustaining a more intricate modeling process? 

4.  **Do stakeholders understand and trust the results from the "best" predictive model?**

    While stakeholders should be engaged in the PA scoping process, the proof-of-concept provides another opportunity for valuable consultation. Sharing results used to investigate the above questions supports transparency and trust in the process. Stakeholders input and questions are essential to the goals of the proof-of-concept - to assess whether and how predictive analytics should be deployed, communicated and used to improve services.  

\

[For further consideration: Are there other questions would you want to investigate in a proof-of-concept?]{style="color:green"}


---
title: "Handling missing data - predictors"
---

![](images/jigsaw.jpg){fig-align="left" width="6in"}
\
Here we focus on how to handle missingness in variables that are potential predictors for our learners:

Some implementations of machine learning algorithms have a built-in way to handle missing data. Others either will not run if the model is fed in data containing missingness or will drop observations with any missing values. We will address missing values before doing any modeling so that the approach will not vary across modeling approaches. Addressing missing data consistently allows us to make a fair comparison of models' performances.

There are many different methods for managing missing data. They typically involve "filling in" - or "imputing" - missing data points with plausible values. Imputation can be a valuable approach to consider, and it is discussed below. But imputation is not the primary strategy. Instead, we should recognize that **missingness may be informative.** Therefore, it is valuable to capture the missingness in our modeling.

### Capturing information in missingness

The idea here is pretty simple. Data may be missing for a reason and that reason may be relate to the outcome we are trying to predict, even if in a small way. We may not know that reason, but we can still account for its potential importance in our model.

For example, take our example in which we are predicting whether a student will graduate on time. One of our potential predictors is a variable that tells us a student's proficiency level on a standardized math test. Students who have missing values for this variable may not have taken the test. There are perhaps lots of reasons students missed the test. It is possible that students who missed the test tend to be absent more often. Therefore, missingness on a math test may tell us something about a student's level of absenteeism. Perhaps some students are exempt from the test - perhaps missingness on the math test is a proxy for being on a different math track. In either case or for a variety of other possible scenarios, we will be better off not imputing information for these students - they may be different from students with nonmissing inforation.

So instead, we add a category for the missingness. Note if before we had an "ordered" categorical variable, for which the categories have a clear and meaningful order or scale, adding a category for missingness now means we have an unordered categorical variable. In R, a `factor` (a class of an R object or of a column in a data frame) is used to represent categorical variables. (By default a factor treats values as unordered categorical variables.) Equivalently, we can create a set of dummies (binary variables with values 0 or 1 indicating whether an observation belongs to the category or not). Note, when we create a set of dummies, we leave one category out, as a reference categroy. For some modeling approaches, including all possible categories can create instable estimation. So for example, if a person is either (1) employed or (2) unemployed, we create a single dummy: for employed. Similarly, if a student is (1) proficient, (2) not proficient or (3) missing proficiency information, we create two dummies: one for proficient and one for missing proficiency information. 

 Here is some R code to illustrate. Here, we have a variable for math test level. Level 1 is not proficient, while Level 2 is proficient. Two of the 5 students do not have any informtion entered in the data.

```{r echo=FALSE}
math.test <- c(1,2,NA,1,2)
math.test.levels <- as.factor(c("1","2","0","1","2"))
math.test.proficient <- c(0,1,0,0,1)
math.test.missing <- c(0,0,1,0,0)
demo.math.test <- data.frame(math.test,math.test.levels,math.test.proficient,math.test.missing)

print(demo.math.test)

```

When the number of missing values for a predictor variable is small, then you will want to combine the "missingness" category with another category. For example, 

### Imputation

For example, a simple version of imputation is to replace missing values of continuous variables with mean or median of the non-missing values, or to replace missing values of categorical variables with the mode. While this practice solves the operational difficulty of missing data, it can potentially create problems. On the last page, we reviewed a list of of reasons why data may be missing. Many of reasons suggest that units of observations (e.g. individuals) with missing data may be different from units without missing data. People who are resistant to reporting their wage may be more likely to have a low wage. Data collection at one site of a business may be more reliable at entering data than another site.

Therefore, if we replace missing values with the mean of nonmissing values, this mean is not a good estimate because it was computed for a different population. When estimating statistical parameters, imputation can introduce bias - that is, it can lead to inflated or undervalued estimates. When fitting a predictive model, this practice can lead to diminished performance because the relationships between predictors (e.g. age and wage) and an outcome (e.g., job retention) can be faulty.

Some analysts focus on doing a really good job at finding plausible values for their imputation. This is a very active area in statistical research. For example, the imputed values may be estimated by modeling - using information throughout the dataset to come up with more plausible values because they are similar to observations with a similar profile across numerous measures (variables). With an approach called "multiple imputation," the modeling for the missing values is repeated multiple times, resulting in multiple complete data sets. This repeated modeling accounts for both sampling uncertainty as well as modeling (specification) uncertainty of imputed values. (E.g., Gelman and Hill (2007)). The multiple complete datasets can be combined in different ways or results from repeated analyses of the multiple datasets can be combined. Multiple imputation methods reduce but do not eliminate bias in filled-in values.

Another common, and simpler approach that is often used with regression is referred to as "dummy variable adjustment." (Cohen and Cohen, 1985) With this approach, a variable's missing values are imputed, and at the same time, a new "dummy" variable is created that indicates whether an observation's value was imputed. It looks like this:

```{r echo=FALSE}

# Creating a mini data frame with missing values
toydata <- data.frame(
  ID = c(1, 2, 3, 4, 5),
  Site = c("A","A","B","B","B"),
  Age = c(25, 32, NA, 28, 40),
  Impute.Age = c(25, 32, 25, 28, 40),
  Miss.Age = c(0,0,1,0,0),
  Wage = c(16.50, 50, 20, NA, 40),
  Impute.Wage = c(16.50, 50, 20, 16.5, 40),
  Miss.Wage = c(0,0,0,1,0),
  JobRetention = c(1,0,1,0,1)
)

print(toydata)
```

For a regression model, we include both new variables for each variable with missingness. That is, we include `Impute.Age` and `Miss.Age` (instead of `Age`) and we include `Impute.Wage` and `Miss.Wage` (instead of `Wage`). Note that in a regression, the choice of the value used for imputation does not affect the coefficient of `Miss.Age` or `Impute.Age`. The coefficient for `Impute.Age` can be regarded as an estimate of the effect of age among the subgroup of those observations that have data on age. The only aspect of the model that depends on the choice of the imputation value is the coefficient on the missing dummies. When we impute with the mean (or the median or mode) of non-missing values, the coefficient of a missingness dummy can be interpreted as the predicted value of Y for individuals with missing data on X minus the predicted value of Y for individuals at the mean of X, controlling for other covariates in the model.

There has been a considerable amount of criticism focused on this approach in the literature. Jones (1996) and Allison (2002) show that, generally in studies using observational data, this approach leads to biased estimates of the coefficients in the regression model.9 Despite the uniform criticism of the method in the literature, however, we believe this approach still warrants consideration in the special case of random assignment evaluations.

---
title: "Learner training & validation with code templates"
html:
  css: styles.css
---

```{r echo=FALSE}
# function to extract code chunks from notebooks
extract_chunk <- function(file, label) {
  lines <- readLines(file)
  inside_chunk <- FALSE
  chunk_lines <- c()

  for (line in lines) {
    if (grepl(sprintf("```\\{r %s", label), line)) {
      inside_chunk <- TRUE
      next
    }

    if (inside_chunk && grepl("```", line)) {
      break
    }

    if (inside_chunk) {
      chunk_lines <- c(chunk_lines, line)
    }
  }

  # You can also print the lines to the console instead of writing to a file
  writeLines(chunk_lines, sprintf("%s.R", label))
}
```

## 02_Learner_Training_and_Validation

All learners are trained in the following code chunk in `02_Learner_Training_and_Validation.Rmd`. The user does not need to enter or edit any code within the chunk. Specifications that were entered in `01_Learner_Specification.Rmd` are loaded in the chunk that precedes this one and passed into the `train_learners()` function.

```{r print_trainLearners, results='asis', echo=FALSE}
extract_chunk("datasets/02_Learner_Training_and_Validation.Rmd", "trainLearners")
code_lines <- readLines("trainLearners.R")
# Print the lines as a formatted code block
cat("```r\n")
cat(code_lines, sep = "\n")
cat("\n```\n")

#cat('<pre style="background-color: lightgray; padding: 10px; border-radius: 5px;">\n')
#cat(code_lines, sep = "\n")
#cat('\n</pre>\n')
```

As commented in the above chunk, the code returns information about couple of performance metrics abbreviated as AUC-PR and AUC-ROC. AUC-PR is the area under the curve (AUC) for a precision recall (PR) curve. AUC-ROC is the area under the curve (AUC) for a receiver operating characteristic (ROC) curve. We will return to explanations of these in a bit.

First, let's focus on the other information that is returned in the above code chunk - the predicted probabilities. For each observation (unit or row) in our data and for each learner, the code returns a predicted probability of the outcome. The predicted probability was estimated by the model corresponding to the learner.

For example, imagine we are predicting whether a student will drop out of high school. Then, for a single student, we get the following information.

```{r echo=FALSE}
allLearnersResults <- readRDS("~/Library/CloudStorage/OneDrive-K.E.PorterConsultingLLC/Git/NCSU-PA-for-Improving-Services/datasets/allLearnersResults.rds")
predProbs <- allLearnersResults$predProbs 
predProbs[which(predProbs$student_id==1),c("student_id","learnerName",".pred_yes","dropout")]
```

The numbers to the left (1, 8000, 15999, 23998) are the row numbers in the data.frame `predProbs`. We can see that we conducted training for four different learners. These four different learners were combinations of two predictor sets ("bm" and "ms") and three modeling approaches ("glm", "lasso" and "random_forest"). The column `.pred_yes` tells us the probability that the outcome is equal to `1`. While not displayed, `predProbs` also contains `pred_no`, the probability that the outcome is equal to `0`. Finally, we also see the actual, observed outcome (`dropout`) for this student.

The predicted probabilities were estimated through the $v$-fold cross-validation procedure. Recall from the earlier section on cross-validation, that each observation takes a turn in a validation fold. After a learner was trained on the $v-1$ other folds, the resulting model was applied to the validation fold, producing a predicted probability for each observation in the validation fold.

## Summarizing the predicted probabilities

```{r plotpredProbs, warning=FALSE, message=FALSE}
source("datasets/plots.R")
source("datasets/learner_training_helpers.R")
source("datasets/performance_metrics.R")

#learnersMetrics <- convert_metrics_wide(modelResults)
#learnersResults$learnersMetrics <- learnersMetrics
probsGraphs <- NULL
learnerNames <- unique(learnersMetrics$learnerName)
for(i in 1:length(learnerNames))
{
  probsGraphs[[i]] <- 
    pred_prob_graph(
      predProbs = learnersResults$predProbs,
      learnerName = learnerNames[i]
    )
}
ggarrange(plotlist = probsGraphs)
```

